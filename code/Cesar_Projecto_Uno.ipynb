{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>61%</td>\n",
       "      <td>535</td>\n",
       "      <td>515</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>55%</td>\n",
       "      <td>544</td>\n",
       "      <td>541</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>93%</td>\n",
       "      <td>513</td>\n",
       "      <td>493</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>9%</td>\n",
       "      <td>559</td>\n",
       "      <td>556</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>63%</td>\n",
       "      <td>542</td>\n",
       "      <td>532</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2%</td>\n",
       "      <td>641</td>\n",
       "      <td>635</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>4%</td>\n",
       "      <td>632</td>\n",
       "      <td>628</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>4%</td>\n",
       "      <td>631</td>\n",
       "      <td>616</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>4%</td>\n",
       "      <td>611</td>\n",
       "      <td>586</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>95%</td>\n",
       "      <td>513</td>\n",
       "      <td>499</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>69%</td>\n",
       "      <td>536</td>\n",
       "      <td>52</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State Participation  Evidence-Based Reading and Writing  \\\n",
       "0                Alabama            5%                                 593   \n",
       "1                 Alaska           38%                                 547   \n",
       "2                Arizona           30%                                 563   \n",
       "3               Arkansas            3%                                 614   \n",
       "4             California           53%                                 531   \n",
       "5               Colorado           11%                                 606   \n",
       "6            Connecticut          100%                                 530   \n",
       "7               Delaware          100%                                 503   \n",
       "8   District of Columbia          100%                                 482   \n",
       "9                Florida           83%                                 520   \n",
       "10               Georgia           61%                                 535   \n",
       "11                Hawaii           55%                                 544   \n",
       "12                 Idaho           93%                                 513   \n",
       "13              Illinois            9%                                 559   \n",
       "14               Indiana           63%                                 542   \n",
       "15                  Iowa            2%                                 641   \n",
       "16                Kansas            4%                                 632   \n",
       "17              Kentucky            4%                                 631   \n",
       "18             Louisiana            4%                                 611   \n",
       "19                 Maine           95%                                 513   \n",
       "20              Maryland           69%                                 536   \n",
       "\n",
       "    Math  Total  \n",
       "0    572   1165  \n",
       "1    533   1080  \n",
       "2    553   1116  \n",
       "3    594   1208  \n",
       "4    524   1055  \n",
       "5    595   1201  \n",
       "6    512   1041  \n",
       "7    492    996  \n",
       "8    468    950  \n",
       "9    497   1017  \n",
       "10   515   1050  \n",
       "11   541   1085  \n",
       "12   493   1005  \n",
       "13   556   1115  \n",
       "14   532   1074  \n",
       "15   635   1275  \n",
       "16   628   1260  \n",
       "17   616   1247  \n",
       "18   586   1198  \n",
       "19   499   1012  \n",
       "20    52   1060  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#couldnt figure out the relative path when i started.\n",
    "sat = pd.read_csv(r'/Users/owner/Desktop/gclone/project_1/project_1/project-1/data/sat_2017.csv')\n",
    "sat.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Participation  English  Math  Reading  Science Composite\n",
       "0  National           60%     20.3  20.7     21.4     21.0      21.0\n",
       "1   Alabama          100%     18.9  18.4     19.7     19.4      19.2\n",
       "2    Alaska           65%     18.7  19.8     20.4     19.9      19.8\n",
       "3   Arizona           62%     18.6  19.8     20.1     19.8      19.7\n",
       "4  Arkansas          100%     18.9  19.0     19.7     19.5      19.4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = pd.read_csv(r'/Users/owner/Desktop/gclone/project_1/project_1/project-1/data/act_2017.csv')\n",
    "act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "SAT: \n",
    "    -I see no NaN values. (.isna)\n",
    "    -It is a DataFrame (type())\n",
    "    -No duplicate values (.duplicate)\n",
    "    -Wyoming has the max values in participation, reading-writing, and math (.max)\n",
    "    -Alabama has the lowest scores, but not the lowest participation rate. (.min) \n",
    "    -shape of 51 rows and 5 columns (.shape) \n",
    "    -Missing total Averages\n",
    "ACT: \n",
    "    -I see no NaN values. (.isna)\n",
    "    -It is a DataFrame (type())\n",
    "    -No duplicate values (.duplicate)\n",
    "    -Wyoming has the max values in participation, reading-writing, and math (.max)\n",
    "    -Alabama has the lowest scores, but not the lowest participation rate. Alabama's participation is much higherhere      than SAT participation  (.min) \n",
    "    - ACT gives us national AVG. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: yes, some values need to be corrected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "        -there were two errors that i didnt realize till I plotted\n",
    "#### 4c.Not so obvious to me:\n",
    "        -Maryland has a 52 isntead of 524, fixed after i merged my dataframes\n",
    "        -Washington D.C vs . Distric of columbia \n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>569.117647</td>\n",
       "      <td>547.627451</td>\n",
       "      <td>1126.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.666901</td>\n",
       "      <td>84.909119</td>\n",
       "      <td>92.494812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>533.500000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>1055.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>644.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Evidence-Based Reading and Writing        Math        Total\n",
       "count                           51.000000   51.000000    51.000000\n",
       "mean                           569.117647  547.627451  1126.098039\n",
       "std                             45.666901   84.909119    92.494812\n",
       "min                            482.000000   52.000000   950.000000\n",
       "25%                            533.500000  522.000000  1055.500000\n",
       "50%                            559.000000  548.000000  1107.000000\n",
       "75%                            613.000000  599.000000  1212.000000\n",
       "max                            644.000000  651.000000  1295.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.040385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>3.151113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>22.525000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               State Participation    English       Math    Reading  \\\n",
       "count             52            52  52.000000  52.000000  52.000000   \n",
       "unique            52            28        NaN        NaN        NaN   \n",
       "top     North Dakota          100%        NaN        NaN        NaN   \n",
       "freq               1            17        NaN        NaN        NaN   \n",
       "mean             NaN           NaN  20.919231  21.173077  22.001923   \n",
       "std              NaN           NaN   2.332132   1.963602   2.048672   \n",
       "min              NaN           NaN  16.300000  18.000000  18.100000   \n",
       "25%              NaN           NaN  19.000000  19.400000  20.475000   \n",
       "50%              NaN           NaN  20.550000  20.900000  21.700000   \n",
       "75%              NaN           NaN  23.300000  23.100000  24.125000   \n",
       "max              NaN           NaN  25.500000  25.300000  26.000000   \n",
       "\n",
       "          Science Composite  \n",
       "count   52.000000        52  \n",
       "unique        NaN        38  \n",
       "top           NaN      20.3  \n",
       "freq          NaN         3  \n",
       "mean    21.040385       NaN  \n",
       "std      3.151113       NaN  \n",
       "min      2.300000       NaN  \n",
       "25%     19.900000       NaN  \n",
       "50%     21.150000       NaN  \n",
       "75%     22.525000       NaN  \n",
       "max     24.900000       NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.describe(include=(np.object, np.number)) #not really sure what this means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat.iloc[20,3] = 524 #I didnt run this till i mereged both dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "sat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?   \n",
    "Sat has 5 columns. Act has 7 column\n",
    "- Which ones are not as they should be?  \n",
    "Participation is an object, should be an int "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6     20.2x"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code  change Participation in act to  \n",
    "act.Participation = act.Participation.map(lambda x: float(x.replace('%',' ')))\n",
    "act.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_percent(x):\n",
    "    return float(x.replace('%',' ')) #def the function, name the function, inputs, return output(what do you want back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_percent('48%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>65.0</td>\n",
       "      <td>561</td>\n",
       "      <td>541</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>64.0</td>\n",
       "      <td>541</td>\n",
       "      <td>534</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14.0</td>\n",
       "      <td>558</td>\n",
       "      <td>528</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642</td>\n",
       "      <td>649</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>626</td>\n",
       "      <td>604</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "46       Virginia           65.0                                 561   541   \n",
       "47     Washington           64.0                                 541   534   \n",
       "48  West Virginia           14.0                                 558   528   \n",
       "49      Wisconsin            3.0                                 642   649   \n",
       "50        Wyoming            3.0                                 626   604   \n",
       "\n",
       "    Total  \n",
       "46   1102  \n",
       "47   1075  \n",
       "48   1086  \n",
       "49   1291  \n",
       "50   1230  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changed sat participation from object to float \n",
    "sat.Participation = sat.Participation.map(lambda x: float(x.replace('%',' ')))\n",
    "sat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6      20.2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act['Composite'] = act['Composite'].str.replace(\"x\", \"\")\n",
    "act.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6      20.2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove x from composite\n",
    "act['Composite'] = act['Composite'].str.replace(\"x\", \"\")\n",
    "act.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6      20.2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove x from composite\n",
    "act['Composite'] = act['Composite'].str.replace(\"x\", \"\")\n",
    "act.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6      20.2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act['Composite'] = act['Composite'].str.replace(\"x\", \"\")\n",
    "act.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "act['Composite'] = act.Composite.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just looking at some stats\n",
    "#act.groupby('Participation', axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(act['Composite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(act.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                  object\n",
       "Participation                         float64\n",
       "Evidence-Based Reading and Writing      int64\n",
       "Math                                    int64\n",
       "Total                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "sat.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation    float64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sat['sat_participation'] = sat.sat_participation.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_new_columns = {\n",
    "    \"State\": \"state\",\n",
    "    \"Participation\": \"sat_participation_2017\",\n",
    "    \"Evidence-Based Reading and Writing\": \"sat_reading_2017\",\n",
    "    \"Math\": \"sat_math_2017\",\n",
    "    \"Total\": \"sat_total_2017\"\n",
    "}\n",
    "\n",
    "sat.rename(columns=sat_new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'sat_participation_2017', 'sat_reading_2017', 'sat_math_2017',\n",
       "       'sat_total_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_new_columns = {\n",
    "    \"State\": \"state\",\n",
    "    \"Participation\": \"act_participation_2017\",\n",
    "    \"English\": \"act_english_2017\",\n",
    "    \"Math\": \"act_math_2017\",\n",
    "    \"Reading\": \"act_reading_2017\",\n",
    "    \"Science\": \"act_science_2017\",\n",
    "    \"Composite\": \"act_composite_2017\"\n",
    "}\n",
    "\n",
    "act.rename(columns=act_new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'act_participation_2017', 'act_english_2017', 'act_math_2017',\n",
       "       'act_reading_2017', 'act_science_2017', 'act_composite_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**State**|*string*|SAT/ACT|State| \n",
    "|**SAT Participation 2017**|*int/float/object*|SAT/ACT| Paricipation rate for each state|\n",
    "|**SAT Reading 2017**|*int/float/object*|SAT/ACT| Reading scores for each state|\n",
    "|**SAT Math 2017**|*int/float/object*|SAT/ACT| Math scores for each state\n",
    "|**SAT Total 2017**|*int/float/object*|SAT/ACT| SAT total scores for each state\n",
    "|**ACT Participation 2017**|*int/float/object*|SAT/ACT| Paricipation rate for each state|\n",
    "|**ACT English 2017**|*int/float/object*|SAT/ACT| English score for each state\n",
    "|**ACT Math 2017**|*int/float/object*|SAT/ACT| Math score for each state\n",
    "|**ACT Reading 2017**|*int/float/object*|SAT/ACT| Reading score for each state\n",
    "|**ACT Science 2017**|*int/float/object*|SAT/ACT| Science score for each state\n",
    "|**ACT Composite 2017**|*int/float/object*|SAT/ACT| ACT Composite for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "0  National                    60.0              20.3           20.7   \n",
       "\n",
       "   act_reading_2017  act_science_2017  act_composite_2017  \n",
       "0              21.4              21.0                21.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "#act.shape\n",
    "act.drop(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "#couldnt get this to work.\n",
    "# frames = [df1, df2]\n",
    "# result = pd.concat(frames, ignore_index=True)\n",
    "# frames= [sat,act]\n",
    "# df_2017 = pd.concat(frames, ignore_index=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38.0</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30.0</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3.0</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53.0</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11.0</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100.0</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100.0</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100.0</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83.0</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "      <td>73.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>61.0</td>\n",
       "      <td>535</td>\n",
       "      <td>515</td>\n",
       "      <td>1050</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>55.0</td>\n",
       "      <td>544</td>\n",
       "      <td>541</td>\n",
       "      <td>1085</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>93.0</td>\n",
       "      <td>513</td>\n",
       "      <td>493</td>\n",
       "      <td>1005</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>9.0</td>\n",
       "      <td>559</td>\n",
       "      <td>556</td>\n",
       "      <td>1115</td>\n",
       "      <td>93.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>63.0</td>\n",
       "      <td>542</td>\n",
       "      <td>532</td>\n",
       "      <td>1074</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>641</td>\n",
       "      <td>635</td>\n",
       "      <td>1275</td>\n",
       "      <td>67.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>632</td>\n",
       "      <td>628</td>\n",
       "      <td>1260</td>\n",
       "      <td>73.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>4.0</td>\n",
       "      <td>631</td>\n",
       "      <td>616</td>\n",
       "      <td>1247</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>4.0</td>\n",
       "      <td>611</td>\n",
       "      <td>586</td>\n",
       "      <td>1198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>95.0</td>\n",
       "      <td>513</td>\n",
       "      <td>499</td>\n",
       "      <td>1012</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>69.0</td>\n",
       "      <td>536</td>\n",
       "      <td>524</td>\n",
       "      <td>1060</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   state  sat_participation_2017  sat_reading_2017  \\\n",
       "0                Alabama                     5.0               593   \n",
       "1                 Alaska                    38.0               547   \n",
       "2                Arizona                    30.0               563   \n",
       "3               Arkansas                     3.0               614   \n",
       "4             California                    53.0               531   \n",
       "5               Colorado                    11.0               606   \n",
       "6            Connecticut                   100.0               530   \n",
       "7               Delaware                   100.0               503   \n",
       "8   District of Columbia                   100.0               482   \n",
       "9                Florida                    83.0               520   \n",
       "10               Georgia                    61.0               535   \n",
       "11                Hawaii                    55.0               544   \n",
       "12                 Idaho                    93.0               513   \n",
       "13              Illinois                     9.0               559   \n",
       "14               Indiana                    63.0               542   \n",
       "15                  Iowa                     2.0               641   \n",
       "16                Kansas                     4.0               632   \n",
       "17              Kentucky                     4.0               631   \n",
       "18             Louisiana                     4.0               611   \n",
       "19                 Maine                    95.0               513   \n",
       "20              Maryland                    69.0               536   \n",
       "\n",
       "    sat_math_2017  sat_total_2017  act_participation_2017  act_english_2017  \\\n",
       "0             572            1165                   100.0              18.9   \n",
       "1             533            1080                    65.0              18.7   \n",
       "2             553            1116                    62.0              18.6   \n",
       "3             594            1208                   100.0              18.9   \n",
       "4             524            1055                    31.0              22.5   \n",
       "5             595            1201                   100.0              20.1   \n",
       "6             512            1041                    31.0              25.5   \n",
       "7             492             996                    18.0              24.1   \n",
       "8             468             950                    32.0              24.4   \n",
       "9             497            1017                    73.0              19.0   \n",
       "10            515            1050                    55.0              21.0   \n",
       "11            541            1085                    90.0              17.8   \n",
       "12            493            1005                    38.0              21.9   \n",
       "13            556            1115                    93.0              21.0   \n",
       "14            532            1074                    35.0              22.0   \n",
       "15            635            1275                    67.0              21.2   \n",
       "16            628            1260                    73.0              21.1   \n",
       "17            616            1247                   100.0              19.6   \n",
       "18            586            1198                   100.0              19.4   \n",
       "19            499            1012                     8.0              24.2   \n",
       "20            524            1060                    28.0              23.3   \n",
       "\n",
       "    act_math_2017  act_reading_2017  act_science_2017  act_composite_2017  \n",
       "0            18.4              19.7              19.4                19.2  \n",
       "1            19.8              20.4              19.9                19.8  \n",
       "2            19.8              20.1              19.8                19.7  \n",
       "3            19.0              19.7              19.5                19.4  \n",
       "4            22.7              23.1              22.2                22.8  \n",
       "5            20.3              21.2              20.9                20.8  \n",
       "6            24.6              25.6              24.6                25.2  \n",
       "7            23.4              24.8              23.6                24.1  \n",
       "8            23.5              24.9              23.5                24.2  \n",
       "9            19.4              21.0              19.4                19.8  \n",
       "10           20.9              22.0              21.3                21.4  \n",
       "11           19.2              19.2              19.3                19.0  \n",
       "12           21.8              23.0              22.1                22.3  \n",
       "13           21.2              21.6              21.3                21.4  \n",
       "14           22.4              23.2              22.3                22.6  \n",
       "15           21.3              22.6              22.1                21.9  \n",
       "16           21.3              22.3              21.7                21.7  \n",
       "17           19.4              20.5              20.1                20.0  \n",
       "18           18.8              19.8              19.6                19.5  \n",
       "19           24.0              24.8              23.7                24.3  \n",
       "20           23.1              24.2               2.3                23.6  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_2017 = pd.merge(sat, act, how='left', on='state', suffixes=('SAT','ACT'))\n",
    "df_2017.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "0  Alabama                     5.0               593            572   \n",
       "\n",
       "   sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "0            1165                   100.0              18.9           18.4   \n",
       "\n",
       "   act_reading_2017  act_science_2017  act_composite_2017  \n",
       "0              19.7              19.4                19.2  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just thinking to hard about this 52\n",
    "# df_2017 = df_2017.sat_math.map(lambda x: 520 if x == 52 else int(x))\n",
    "# df_2017.iloc[20,3] This fucked up all my data 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.0</td>\n",
       "      <td>644</td>\n",
       "      <td>651</td>\n",
       "      <td>1295</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sat_participation_2017  sat_reading_2017  sat_math_2017  sat_total_2017  \\\n",
       "min                     2.0               482            468             950   \n",
       "max                   100.0               644            651            1295   \n",
       "\n",
       "     act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "min                     8.0              16.3           18.0   \n",
       "max                   100.0              25.5           25.3   \n",
       "\n",
       "     act_reading_2017  act_science_2017  act_composite_2017  \n",
       "min              18.1               2.3                17.8  \n",
       "max              26.0              24.9                25.5  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_agg = df_2017.agg({\n",
    "    'sat_participation_2017': ['min','max'],\n",
    "    'sat_reading_2017': ['min','max'],\n",
    "    'sat_math_2017': ['min','max'],\n",
    "    'sat_total_2017': ['min','max'],\n",
    "    'act_participation_2017': ['min','max'],\n",
    "    'act_english_2017': ['min','max'],\n",
    "    'act_math_2017': ['min','max'],\n",
    "    'act_reading_2017': ['min','max'],\n",
    "    'act_science_2017': ['min','max'],\n",
    "    'act_composite_2017': ['min','max'],\n",
    "})\n",
    "df_2017_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.to_csv('combined_2017.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38.0</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30.0</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3.0</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53.0</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "0     Alabama                     5.0               593            572   \n",
       "1      Alaska                    38.0               547            533   \n",
       "2     Arizona                    30.0               563            553   \n",
       "3    Arkansas                     3.0               614            594   \n",
       "4  California                    53.0               531            524   \n",
       "\n",
       "   sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "0            1165                   100.0              18.9           18.4   \n",
       "1            1080                    65.0              18.7           19.8   \n",
       "2            1116                    62.0              18.6           19.8   \n",
       "3            1208                   100.0              18.9           19.0   \n",
       "4            1055                    31.0              22.5           22.7   \n",
       "\n",
       "   act_reading_2017  act_science_2017  act_composite_2017  \n",
       "0              19.7              19.4                19.2  \n",
       "1              20.4              19.9                19.8  \n",
       "2              20.1              19.8                19.7  \n",
       "3              19.7              19.5                19.4  \n",
       "4              23.1              22.2                22.8  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            6%                                 595   571   1166\n",
       "1      Alaska           43%                                 562   544   1106\n",
       "2     Arizona           29%                                 577   572   1149\n",
       "3    Arkansas            5%                                 592   576   1168\n",
       "4  California           60%                                 540   536   1076"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018 = pd.read_csv(r'/Users/owner/Desktop/gclone/project_1/project_1/project-1/data/East_Coast_Data_Entry - SAT 2018.csv')\n",
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33%</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27%</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Composite\n",
       "0     Alabama          100%       19.1\n",
       "1      Alaska           33%       20.8\n",
       "2     Arizona           66%       19.2\n",
       "3    Arkansas          100%       19.4\n",
       "4  California           27%       22.7"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018 = pd.read_csv(r'/Users/owner/Desktop/gclone/project_1/project_1/project-1/data/East_Coast_Data_Entry - ACT 2018.csv')\n",
    "act_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>28%</td>\n",
       "      <td>519</td>\n",
       "      <td>506</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>535</td>\n",
       "      <td>519</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>505</td>\n",
       "      <td>492</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>92%</td>\n",
       "      <td>497</td>\n",
       "      <td>480</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>97%</td>\n",
       "      <td>522</td>\n",
       "      <td>493</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            6%                                 595   \n",
       "1                Alaska           43%                                 562   \n",
       "2               Arizona           29%                                 577   \n",
       "3              Arkansas            5%                                 592   \n",
       "4            California           60%                                 540   \n",
       "5              Colorado           28%                                 519   \n",
       "6           Connecticut          100%                                 535   \n",
       "7              Delaware          100%                                 505   \n",
       "8  District of Columbia           92%                                 497   \n",
       "9               Florida           97%                                 522   \n",
       "\n",
       "   Math  Total  \n",
       "0   571   1166  \n",
       "1   544   1106  \n",
       "2   572   1149  \n",
       "3   576   1168  \n",
       "4   536   1076  \n",
       "5   506   1025  \n",
       "6   519   1054  \n",
       "7   492    997  \n",
       "8   480    977  \n",
       "9   493   1015  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33%</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27%</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>30%</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>26%</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>17%</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>32%</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              State Participation  Composite\n",
       "0           Alabama          100%       19.1\n",
       "1            Alaska           33%       20.8\n",
       "2           Arizona           66%       19.2\n",
       "3          Arkansas          100%       19.4\n",
       "4        California           27%       22.7\n",
       "5          Colorado           30%       23.9\n",
       "6       Connecticut           26%       25.6\n",
       "7          Delaware           17%       23.8\n",
       "8  Washington, D.C.           32%       23.6\n",
       "9           Florida           66%       19.9"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thx to everyone on slack they brought this to my attention\n",
    "act_2018.iloc[8, 0] = act_2018.iloc[8, 0].replace('Washington, D.C.', 'District of Columbia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "sat_2018: \n",
    "    -I see no NaN values. (.isna)\n",
    "    -It is a DataFrame (type())\n",
    "    -No duplicate values (.duplicate)\n",
    "    -Wyoming has the max values in participation, reading-writing, and math (.max)\n",
    "    -Alabama has the lowest scores, but not the lowest participation rate. (.min) \n",
    "    -shape of 51 rows and 5 columns (.shape) \n",
    "    -Missing total Averages\n",
    "    -sat_2018 gives \n",
    "act_2018: \n",
    "    -I see no NaN values. (.isna)\n",
    "    -It is a DataFrame (type())\n",
    "    -No duplicate values (.duplicate)\n",
    "    -Wyoming has the max values in participation, reading-writing, and math (.max)\n",
    "    -Alabama has the lowest scores, but not the lowest participation rate. Alabama's participation is much higherhere      than SAT participation  (.min) \n",
    "    - ACT gives us national AVG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            6%                                 595   571   1166\n",
       "1      Alaska           43%                                 562   544   1106\n",
       "2     Arizona           29%                                 577   572   1149\n",
       "3    Arkansas            5%                                 592   576   1168\n",
       "4  California           60%                                 540   536   1076"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>69.0</td>\n",
       "      <td>543</td>\n",
       "      <td>538</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>641</td>\n",
       "      <td>653</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>633</td>\n",
       "      <td>625</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>National</td>\n",
       "      <td>51.0</td>\n",
       "      <td>568</td>\n",
       "      <td>558</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "47     Washington           69.0                                 543   538   \n",
       "48  West Virginia           28.0                                 513   486   \n",
       "49      Wisconsin            3.0                                 641   653   \n",
       "50        Wyoming            3.0                                 633   625   \n",
       "51       National           51.0                                 568   558   \n",
       "\n",
       "    Total  \n",
       "47   1081  \n",
       "48    999  \n",
       "49   1294  \n",
       "50   1258  \n",
       "51   1126  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code  change Participation in sat_2018 to a float with out the '%'  \n",
    "sat_2018.Participation = sat_2018.Participation.map(lambda x: float(x.replace('%',' ')))\n",
    "sat_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>National</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  Composite\n",
       "47     Washington           24.0       22.2\n",
       "48  West Virginia           65.0       20.3\n",
       "49      Wisconsin          100.0       20.5\n",
       "50        Wyoming          100.0       20.0\n",
       "51       National           50.0       21.5"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code  change Participation in sat_2018 to a float with out the '%'  \n",
    "act_2018.Participation = act_2018.Participation.map(lambda x: float(x.replace('%',' ')))\n",
    "act_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>69.0</td>\n",
       "      <td>543</td>\n",
       "      <td>538</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>641</td>\n",
       "      <td>653</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>633</td>\n",
       "      <td>625</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>National</td>\n",
       "      <td>51.0</td>\n",
       "      <td>568</td>\n",
       "      <td>558</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "47     Washington           69.0                                 543   538   \n",
       "48  West Virginia           28.0                                 513   486   \n",
       "49      Wisconsin            3.0                                 641   653   \n",
       "50        Wyoming            3.0                                 633   625   \n",
       "51       National           51.0                                 568   558   \n",
       "\n",
       "    Total  \n",
       "47   1081  \n",
       "48    999  \n",
       "49   1294  \n",
       "50   1258  \n",
       "51   1126  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      object\n",
       "sat_participation_2017    float64\n",
       "sat_reading_2017            int64\n",
       "sat_math_2017               int64\n",
       "sat_total_2017              int64\n",
       "act_participation_2017    float64\n",
       "act_english_2017          float64\n",
       "act_math_2017             float64\n",
       "act_reading_2017          float64\n",
       "act_science_2017          float64\n",
       "act_composite_2017        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                  object\n",
       "Participation                         float64\n",
       "Evidence-Based Reading and Writing      int64\n",
       "Math                                    int64\n",
       "Total                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation    float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.346154</td>\n",
       "      <td>567.711538</td>\n",
       "      <td>558.442308</td>\n",
       "      <td>1126.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.941865</td>\n",
       "      <td>44.864649</td>\n",
       "      <td>48.977551</td>\n",
       "      <td>93.513632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>521.750000</td>\n",
       "      <td>1063.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>1102.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>76.750000</td>\n",
       "      <td>615.750000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>1298.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Participation  Evidence-Based Reading and Writing        Math  \\\n",
       "count      52.000000                           52.000000   52.000000   \n",
       "mean       45.346154                          567.711538  558.442308   \n",
       "std        36.941865                           44.864649   48.977551   \n",
       "min         2.000000                          497.000000  480.000000   \n",
       "25%         4.750000                          535.000000  521.750000   \n",
       "50%        49.500000                          558.000000  547.000000   \n",
       "75%        76.750000                          615.750000  598.000000   \n",
       "max       100.000000                          643.000000  655.000000   \n",
       "\n",
       "             Total  \n",
       "count    52.000000  \n",
       "mean   1126.153846  \n",
       "std      93.513632  \n",
       "min     977.000000  \n",
       "25%    1063.500000  \n",
       "50%    1102.500000  \n",
       "75%    1215.000000  \n",
       "max    1298.000000  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45.346154</td>\n",
       "      <td>567.711538</td>\n",
       "      <td>558.442308</td>\n",
       "      <td>1126.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.941865</td>\n",
       "      <td>44.864649</td>\n",
       "      <td>48.977551</td>\n",
       "      <td>93.513632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>521.750000</td>\n",
       "      <td>1063.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>1102.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>615.750000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>1298.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               State  Participation  Evidence-Based Reading and Writing  \\\n",
       "count             52      52.000000                           52.000000   \n",
       "unique            52            NaN                                 NaN   \n",
       "top     North Dakota            NaN                                 NaN   \n",
       "freq               1            NaN                                 NaN   \n",
       "mean             NaN      45.346154                          567.711538   \n",
       "std              NaN      36.941865                           44.864649   \n",
       "min              NaN       2.000000                          497.000000   \n",
       "25%              NaN       4.750000                          535.000000   \n",
       "50%              NaN      49.500000                          558.000000   \n",
       "75%              NaN      76.750000                          615.750000   \n",
       "max              NaN     100.000000                          643.000000   \n",
       "\n",
       "              Math        Total  \n",
       "count    52.000000    52.000000  \n",
       "unique         NaN          NaN  \n",
       "top            NaN          NaN  \n",
       "freq           NaN          NaN  \n",
       "mean    558.442308  1126.153846  \n",
       "std      48.977551    93.513632  \n",
       "min     480.000000   977.000000  \n",
       "25%     521.750000  1063.500000  \n",
       "50%     547.000000  1102.500000  \n",
       "75%     598.000000  1215.000000  \n",
       "max     655.000000  1298.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.describe(include=(np.object, np.number, np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>21.496154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.740939</td>\n",
       "      <td>2.090779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>19.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               State  Participation  Composite\n",
       "count             52      52.000000  52.000000\n",
       "unique            52            NaN        NaN\n",
       "top     North Dakota            NaN        NaN\n",
       "freq               1            NaN        NaN\n",
       "mean             NaN      61.500000  21.496154\n",
       "std              NaN      33.740939   2.090779\n",
       "min              NaN       7.000000  17.700000\n",
       "25%              NaN      29.250000  19.975000\n",
       "50%              NaN      65.500000  21.300000\n",
       "75%              NaN     100.000000  23.625000\n",
       "max              NaN     100.000000  25.600000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.describe(include=(np.object, np.number, np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38.0</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30.0</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3.0</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53.0</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "0     Alabama                     5.0               593            572   \n",
       "1      Alaska                    38.0               547            533   \n",
       "2     Arizona                    30.0               563            553   \n",
       "3    Arkansas                     3.0               614            594   \n",
       "4  California                    53.0               531            524   \n",
       "\n",
       "   sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "0            1165                   100.0              18.9           18.4   \n",
       "1            1080                    65.0              18.7           19.8   \n",
       "2            1116                    62.0              18.6           19.8   \n",
       "3            1208                   100.0              18.9           19.0   \n",
       "4            1055                    31.0              22.5           22.7   \n",
       "\n",
       "   act_reading_2017  act_science_2017  act_composite_2017  \n",
       "0              19.7              19.4                19.2  \n",
       "1              20.4              19.9                19.8  \n",
       "2              20.1              19.8                19.7  \n",
       "3              19.7              19.5                19.4  \n",
       "4              23.1              22.2                22.8  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6.0</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43.0</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.0</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            6.0                                 595   571   1166\n",
       "1      Alaska           43.0                                 562   544   1106\n",
       "2     Arizona           29.0                                 577   572   1149\n",
       "3    Arkansas            5.0                                 592   576   1168\n",
       "4  California           60.0                                 540   536   1076"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2018_new_columns = {\n",
    "    \"State\": \"state\",\n",
    "    \"Participation\": \"sat_participation_2018\",\n",
    "    \"Evidence-Based Reading and Writing\": \"sat_reading_2018\",\n",
    "    \"Math\": \"sat_math_2018\",\n",
    "    \"Total\": \"sat_total_2018\"\n",
    "}\n",
    "\n",
    "sat_2018.rename(columns=sat2018_new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "act2018_new_columns = {\n",
    "    \"State\": \"state\",\n",
    "    \"Participation\": \"act_participation_2018\",\n",
    "    \"English\": \"act_english_2018\",\n",
    "    \"Math\": \"act_math_2018\",\n",
    "    \"Reading\": \"act_reading_2018\",\n",
    "    \"Science\": \"act_science_2018\",\n",
    "    \"Composite\": \"act_composite_2018\"\n",
    "}\n",
    "\n",
    "act_2018.rename(columns=act2018_new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'act_participation_2018', 'act_composite_2018'], dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2018</th>\n",
       "      <th>sat_reading_2018</th>\n",
       "      <th>sat_math_2018</th>\n",
       "      <th>sat_total_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>69.0</td>\n",
       "      <td>543</td>\n",
       "      <td>538</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>641</td>\n",
       "      <td>653</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>633</td>\n",
       "      <td>625</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>National</td>\n",
       "      <td>51.0</td>\n",
       "      <td>568</td>\n",
       "      <td>558</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  sat_participation_2018  sat_reading_2018  sat_math_2018  \\\n",
       "47     Washington                    69.0               543            538   \n",
       "48  West Virginia                    28.0               513            486   \n",
       "49      Wisconsin                     3.0               641            653   \n",
       "50        Wyoming                     3.0               633            625   \n",
       "51       National                    51.0               568            558   \n",
       "\n",
       "    sat_total_2018  \n",
       "47            1081  \n",
       "48             999  \n",
       "49            1294  \n",
       "50            1258  \n",
       "51            1126  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2018</th>\n",
       "      <th>sat_reading_2018</th>\n",
       "      <th>sat_math_2018</th>\n",
       "      <th>sat_total_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>68.0</td>\n",
       "      <td>567</td>\n",
       "      <td>550</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>69.0</td>\n",
       "      <td>543</td>\n",
       "      <td>538</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>641</td>\n",
       "      <td>653</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>633</td>\n",
       "      <td>625</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  sat_participation_2018  sat_reading_2018  sat_math_2018  \\\n",
       "46       Virginia                    68.0               567            550   \n",
       "47     Washington                    69.0               543            538   \n",
       "48  West Virginia                    28.0               513            486   \n",
       "49      Wisconsin                     3.0               641            653   \n",
       "50        Wyoming                     3.0               633            625   \n",
       "\n",
       "    sat_total_2018  \n",
       "46            1117  \n",
       "47            1081  \n",
       "48             999  \n",
       "49            1294  \n",
       "50            1258  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.drop(51, inplace=True)\n",
    "sat_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation_2018</th>\n",
       "      <th>act_composite_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  act_participation_2018  act_composite_2018\n",
       "46       Virginia                    24.0                23.9\n",
       "47     Washington                    24.0                22.2\n",
       "48  West Virginia                    65.0                20.3\n",
       "49      Wisconsin                   100.0                20.5\n",
       "50        Wyoming                   100.0                20.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.drop(51, inplace=True)\n",
    "act_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>65.0</td>\n",
       "      <td>561</td>\n",
       "      <td>541</td>\n",
       "      <td>1102</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>64.0</td>\n",
       "      <td>541</td>\n",
       "      <td>534</td>\n",
       "      <td>1075</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14.0</td>\n",
       "      <td>558</td>\n",
       "      <td>528</td>\n",
       "      <td>1086</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642</td>\n",
       "      <td>649</td>\n",
       "      <td>1291</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3.0</td>\n",
       "      <td>626</td>\n",
       "      <td>604</td>\n",
       "      <td>1230</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "46       Virginia                    65.0               561            541   \n",
       "47     Washington                    64.0               541            534   \n",
       "48  West Virginia                    14.0               558            528   \n",
       "49      Wisconsin                     3.0               642            649   \n",
       "50        Wyoming                     3.0               626            604   \n",
       "\n",
       "    sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "46            1102                    29.0              23.5           23.3   \n",
       "47            1075                    29.0              20.9           21.9   \n",
       "48            1086                    69.0              20.0           19.4   \n",
       "49            1291                   100.0              19.7           20.4   \n",
       "50            1230                   100.0              19.4           19.8   \n",
       "\n",
       "    act_reading_2017  act_science_2017  act_composite_2017  \n",
       "46              24.6              23.5                23.8  \n",
       "47              22.1              22.0                21.9  \n",
       "48              21.2              20.5                20.4  \n",
       "49              20.6              20.9                20.5  \n",
       "50              20.8              20.6                20.2  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation_2018</th>\n",
       "      <th>act_composite_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66.0</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act_participation_2018  act_composite_2018\n",
       "0     Alabama                   100.0                19.1\n",
       "1      Alaska                    33.0                20.8\n",
       "2     Arizona                    66.0                19.2\n",
       "3    Arkansas                   100.0                19.4\n",
       "4  California                    27.0                22.7"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.head() # just checking, gotta remind myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2018</th>\n",
       "      <th>sat_reading_2018</th>\n",
       "      <th>sat_math_2018</th>\n",
       "      <th>sat_total_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6.0</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43.0</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.0</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  sat_participation_2018  sat_reading_2018  sat_math_2018  \\\n",
       "0     Alabama                     6.0               595            571   \n",
       "1      Alaska                    43.0               562            544   \n",
       "2     Arizona                    29.0               577            572   \n",
       "3    Arkansas                     5.0               592            576   \n",
       "4  California                    60.0               540            536   \n",
       "\n",
       "   sat_total_2018  \n",
       "0            1166  \n",
       "1            1106  \n",
       "2            1149  \n",
       "3            1168  \n",
       "4            1076  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.merge(sat_2018, act_2018, how='left', on='state')\n",
    "#df_2018.iloc[10:15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>61.0</td>\n",
       "      <td>535</td>\n",
       "      <td>515</td>\n",
       "      <td>1050</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>55.0</td>\n",
       "      <td>544</td>\n",
       "      <td>541</td>\n",
       "      <td>1085</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>93.0</td>\n",
       "      <td>513</td>\n",
       "      <td>493</td>\n",
       "      <td>1005</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>9.0</td>\n",
       "      <td>559</td>\n",
       "      <td>556</td>\n",
       "      <td>1115</td>\n",
       "      <td>93.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>63.0</td>\n",
       "      <td>542</td>\n",
       "      <td>532</td>\n",
       "      <td>1074</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "10   Georgia                    61.0               535            515   \n",
       "11    Hawaii                    55.0               544            541   \n",
       "12     Idaho                    93.0               513            493   \n",
       "13  Illinois                     9.0               559            556   \n",
       "14   Indiana                    63.0               542            532   \n",
       "\n",
       "    sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "10            1050                    55.0              21.0           20.9   \n",
       "11            1085                    90.0              17.8           19.2   \n",
       "12            1005                    38.0              21.9           21.8   \n",
       "13            1115                    93.0              21.0           21.2   \n",
       "14            1074                    35.0              22.0           22.4   \n",
       "\n",
       "    act_reading_2017  act_science_2017  act_composite_2017  \n",
       "10              22.0              21.3                21.4  \n",
       "11              19.2              19.3                19.0  \n",
       "12              23.0              22.1                22.3  \n",
       "13              21.6              21.3                21.4  \n",
       "14              23.2              22.3                22.6  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.iloc[10:15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_total_2017</th>\n",
       "      <th>act_participation_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "      <th>sat_participation_2018</th>\n",
       "      <th>sat_reading_2018</th>\n",
       "      <th>sat_math_2018</th>\n",
       "      <th>sat_total_2018</th>\n",
       "      <th>act_participation_2018</th>\n",
       "      <th>act_composite_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38.0</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30.0</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>66.0</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3.0</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53.0</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  sat_participation_2017  sat_reading_2017  sat_math_2017  \\\n",
       "0     Alabama                     5.0               593            572   \n",
       "1      Alaska                    38.0               547            533   \n",
       "2     Arizona                    30.0               563            553   \n",
       "3    Arkansas                     3.0               614            594   \n",
       "4  California                    53.0               531            524   \n",
       "\n",
       "   sat_total_2017  act_participation_2017  act_english_2017  act_math_2017  \\\n",
       "0            1165                   100.0              18.9           18.4   \n",
       "1            1080                    65.0              18.7           19.8   \n",
       "2            1116                    62.0              18.6           19.8   \n",
       "3            1208                   100.0              18.9           19.0   \n",
       "4            1055                    31.0              22.5           22.7   \n",
       "\n",
       "   act_reading_2017  act_science_2017  act_composite_2017  \\\n",
       "0              19.7              19.4                19.2   \n",
       "1              20.4              19.9                19.8   \n",
       "2              20.1              19.8                19.7   \n",
       "3              19.7              19.5                19.4   \n",
       "4              23.1              22.2                22.8   \n",
       "\n",
       "   sat_participation_2018  sat_reading_2018  sat_math_2018  sat_total_2018  \\\n",
       "0                     6.0               595            571            1166   \n",
       "1                    43.0               562            544            1106   \n",
       "2                    29.0               577            572            1149   \n",
       "3                     5.0               592            576            1168   \n",
       "4                    60.0               540            536            1076   \n",
       "\n",
       "   act_participation_2018  act_composite_2018  \n",
       "0                   100.0                19.1  \n",
       "1                    33.0                20.8  \n",
       "2                    66.0                19.2  \n",
       "3                   100.0                19.4  \n",
       "4                    27.0                22.7  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_2018=pd.merge(df_2017,df_2018, on='state')\n",
    "df_2017_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      object\n",
       "sat_participation_2017    float64\n",
       "sat_reading_2017            int64\n",
       "sat_math_2017               int64\n",
       "sat_total_2017              int64\n",
       "act_participation_2017    float64\n",
       "act_english_2017          float64\n",
       "act_math_2017             float64\n",
       "act_reading_2017          float64\n",
       "act_science_2017          float64\n",
       "act_composite_2017        float64\n",
       "sat_participation_2018    float64\n",
       "sat_reading_2018            int64\n",
       "sat_math_2018               int64\n",
       "sat_total_2018              int64\n",
       "act_participation_2018    float64\n",
       "act_composite_2018        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_2018.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat_participation_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>39.803922</td>\n",
       "      <td>35.276632</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_reading_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>569.117647</td>\n",
       "      <td>45.666901</td>\n",
       "      <td>482.0</td>\n",
       "      <td>533.50</td>\n",
       "      <td>559.0</td>\n",
       "      <td>613.00</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_math_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>556.882353</td>\n",
       "      <td>47.121395</td>\n",
       "      <td>468.0</td>\n",
       "      <td>523.50</td>\n",
       "      <td>548.0</td>\n",
       "      <td>599.00</td>\n",
       "      <td>651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_total_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1126.098039</td>\n",
       "      <td>92.494812</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1055.50</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>1212.00</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_participation_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>65.254902</td>\n",
       "      <td>32.140842</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_english_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.931373</td>\n",
       "      <td>2.353677</td>\n",
       "      <td>16.3</td>\n",
       "      <td>19.00</td>\n",
       "      <td>20.7</td>\n",
       "      <td>23.30</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_math_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.182353</td>\n",
       "      <td>1.981989</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.40</td>\n",
       "      <td>20.9</td>\n",
       "      <td>23.10</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_reading_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.013725</td>\n",
       "      <td>2.067271</td>\n",
       "      <td>18.1</td>\n",
       "      <td>20.45</td>\n",
       "      <td>21.8</td>\n",
       "      <td>24.15</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_science_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.041176</td>\n",
       "      <td>3.182463</td>\n",
       "      <td>2.3</td>\n",
       "      <td>19.90</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.75</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_composite_2017</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.519608</td>\n",
       "      <td>2.020695</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.80</td>\n",
       "      <td>21.4</td>\n",
       "      <td>23.60</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_participation_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>45.235294</td>\n",
       "      <td>37.300718</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>48.0</td>\n",
       "      <td>77.50</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_reading_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>567.705882</td>\n",
       "      <td>45.311056</td>\n",
       "      <td>497.0</td>\n",
       "      <td>535.00</td>\n",
       "      <td>554.0</td>\n",
       "      <td>616.50</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_math_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>558.450980</td>\n",
       "      <td>49.464862</td>\n",
       "      <td>480.0</td>\n",
       "      <td>521.50</td>\n",
       "      <td>547.0</td>\n",
       "      <td>601.00</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_total_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1126.156863</td>\n",
       "      <td>94.444136</td>\n",
       "      <td>977.0</td>\n",
       "      <td>1063.00</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1220.00</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_participation_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>61.725490</td>\n",
       "      <td>34.037085</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.50</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_composite_2018</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.496078</td>\n",
       "      <td>2.111583</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.95</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.65</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count         mean        std    min      25%     50%  \\\n",
       "sat_participation_2017   51.0    39.803922  35.276632    2.0     4.00    38.0   \n",
       "sat_reading_2017         51.0   569.117647  45.666901  482.0   533.50   559.0   \n",
       "sat_math_2017            51.0   556.882353  47.121395  468.0   523.50   548.0   \n",
       "sat_total_2017           51.0  1126.098039  92.494812  950.0  1055.50  1107.0   \n",
       "act_participation_2017   51.0    65.254902  32.140842    8.0    31.00    69.0   \n",
       "act_english_2017         51.0    20.931373   2.353677   16.3    19.00    20.7   \n",
       "act_math_2017            51.0    21.182353   1.981989   18.0    19.40    20.9   \n",
       "act_reading_2017         51.0    22.013725   2.067271   18.1    20.45    21.8   \n",
       "act_science_2017         51.0    21.041176   3.182463    2.3    19.90    21.3   \n",
       "act_composite_2017       51.0    21.519608   2.020695   17.8    19.80    21.4   \n",
       "sat_participation_2018   51.0    45.235294  37.300718    2.0     4.50    48.0   \n",
       "sat_reading_2018         51.0   567.705882  45.311056  497.0   535.00   554.0   \n",
       "sat_math_2018            51.0   558.450980  49.464862  480.0   521.50   547.0   \n",
       "sat_total_2018           51.0  1126.156863  94.444136  977.0  1063.00  1099.0   \n",
       "act_participation_2018   51.0    61.725490  34.037085    7.0    28.50    66.0   \n",
       "act_composite_2018       51.0    21.496078   2.111583   17.7    19.95    21.3   \n",
       "\n",
       "                            75%     max  \n",
       "sat_participation_2017    66.00   100.0  \n",
       "sat_reading_2017         613.00   644.0  \n",
       "sat_math_2017            599.00   651.0  \n",
       "sat_total_2017          1212.00  1295.0  \n",
       "act_participation_2017   100.00   100.0  \n",
       "act_english_2017          23.30    25.5  \n",
       "act_math_2017             23.10    25.3  \n",
       "act_reading_2017          24.15    26.0  \n",
       "act_science_2017          22.75    24.9  \n",
       "act_composite_2017        23.60    25.5  \n",
       "sat_participation_2018    77.50   100.0  \n",
       "sat_reading_2018         616.50   643.0  \n",
       "sat_math_2018            601.00   655.0  \n",
       "sat_total_2018          1220.00  1298.0  \n",
       "act_participation_2018   100.00   100.0  \n",
       "act_composite_2018        23.65    25.6  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "df_2017_2018.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# def mean(data):\n",
    "#     return float(sum(data) / len(data))\n",
    "\n",
    "# def variance(data):\n",
    "#     mu = mean(data)\n",
    "#     return mean([(x - mu) ** 2 for x in data])\n",
    "\n",
    "# def stddev(data,column_name):\n",
    "#     return math.sqrt(variance(data))\n",
    "# stddev(df_2017_2018,'sat_reading_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def std(dataframe, column_name):\n",
    "#     mu = dataframe[column_name].mean()\n",
    "#     var = sum([((x-mu)**2) for x in dataframe[column_name]])/len(dataframe)\n",
    "#     std = var**0.5\n",
    "#     return std\n",
    "# std(df_2017_2018)   #joey told me we didnt need the column_name and made it work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      object\n",
       "sat_participation_2017    float64\n",
       "sat_reading_2017            int64\n",
       "sat_math_2017               int64\n",
       "sat_total_2017              int64\n",
       "act_participation_2017    float64\n",
       "act_english_2017          float64\n",
       "act_math_2017             float64\n",
       "act_reading_2017          float64\n",
       "act_science_2017          float64\n",
       "act_composite_2017        float64\n",
       "sat_participation_2018    float64\n",
       "sat_reading_2018            int64\n",
       "sat_math_2018               int64\n",
       "sat_total_2018              int64\n",
       "act_participation_2018    float64\n",
       "act_composite_2018        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.97751133618255"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def std(dataframe):\n",
    "    mu = dataframe.mean()\n",
    "    var = sum([((x-mu)**2) for x in dataframe])/len(dataframe)\n",
    "    std = var**0.5\n",
    "    return std\n",
    "std(df_2017_2018['sat_math_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018_agg= df_2017_2018.agg(\"mean\", axis=\"index\")\n",
    "df_2017_2018_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varience_all = df_2017_2018_agg.var(axis=0)\n",
    "\n",
    "# varience_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_state = df_2017_2018.drop(['state'], axis=1)\n",
    "# no_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# def stddev(data):\n",
    "#     variance=varience_all\n",
    "#     return math.sqrt(variance(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(varience_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in varience_all:\n",
    "#     print(math.sqrt(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    {'sat_participation_2017': std(df_2017_2018['sat_participation_2017'])},\n",
    "    {'sat_reading_2017' : std(df_2017_2018['sat_reading_2017'])},\n",
    "    {'sat_math_2017' : std(df_2017_2018['sat_math_2017'])},\n",
    "    {'' : std(df_2017_2018[''])},\n",
    ")\n",
    "mask  I stopped here and searched for a way i didnt have to type all this shit out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd= df_2017_2018.iloc[:,1:]\n",
    "sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sd_2= sd.apply(std)\n",
    "sd_2_dict = dict(sd_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_2_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_2017_2018) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum and maximum participation rate for SAT and ACT for 2017:\n",
    "\n",
    "min(df_2017_2018['sat_participation_2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017 SAT participation max,min depending on the ascending\n",
    "df_2017_2018.sort_values(by='sat_participation_2017', ascending=True).head(10)#[['state', 'sat_participation_2017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 SAT participation max, min depending on the ascneding\n",
    "df_2017_2018.sort_values(by='sat_participation_2018', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 ACT parti max,min depending on the ascending \n",
    "df_2017_2018.sort_values(by='act_participation_2017', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 ACT parti max,min depending on the ascending\n",
    "df_2017_2018.sort_values(by='act_participation_2018', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which states have the highest and lowest mean total/composite scores for the:\n",
    "df_2017_2018.sort_values(by='sat_total_2017', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another fuck up \n",
    "#(df_2017_2018.groupby('sat_participation_2017').min().head()) & (df_2017_2018.groupby('act_participation_2017').min().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max,min for 2018(change the asceding to get the min)\n",
    "df_2017_2018.sort_values(by='act_composite_2018', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##max,min for 2017 (change the asceding to get the min)\n",
    "df_2017_2018.sort_values(by='act_composite_2017', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max,min for 2017. (change the asceding to get the min)\n",
    "df_2017_2018.sort_values(by='sat_total_2017', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max,min for 2018(change the asceding to get the min)\n",
    "df_2017_2018.sort_values(by='sat_total_2018', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which states have the highest and lowest mean total/composite scores for the:\n",
    "# this gives me that total, not the states\n",
    "df_2017_2018_mean = df_2017_2018.agg({\n",
    "    'sat_total_2017': ['mean'],\n",
    "    'act_composite_2018': ['mean'],\n",
    "})\n",
    "df_2017_2018_mean\n",
    "\n",
    "#df_2017_2018.loc[:,'sat_total_2017'].mean() another way of saying the same thing, but for a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018[['sat_total_2017']].mean(axis=1)\n",
    "test = df_2017_2018.sort_values(by='sat_total_2017', ascending=True).mean()\n",
    "test.head() # not even sure what this does "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.loc[:,'sat_total_2017'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018_agg = df_2017_2018.agg({\n",
    "    'sat_participation_2017': ['min','max','mean','std','median'],\n",
    "    'sat_reading_2017': ['min','max','mean','std','median'],\n",
    "    'sat_math_2017': ['min','max','mean','std','median'],\n",
    "    'sat_total_2017': ['min','max','mean','std','median'],\n",
    "    'act_participation_2017': ['min','max','mean','std','median'],\n",
    "    'act_english_2017': ['min','max','mean','std','median'],\n",
    "    'act_math_2017': ['min','max','mean','std','median'],\n",
    "    'act_reading_2017': ['min','max','mean','std','median'],\n",
    "    'act_science_2017': ['min','max','mean','std','median'],\n",
    "    'act_composite_2017': ['min','max','mean','std','median'],\n",
    "    'sat_participation_2018': ['min','max','mean','std','median'],\n",
    "    'sat_reading_2018': ['min','max','mean','std','median'],\n",
    "    'sat_math_2018': ['min','max','mean','std','median'],\n",
    "    'sat_total_2018': ['min','max','mean','std','median'],\n",
    "    'act_participation_2018': ['min','max','mean','std','median'],\n",
    "    'act_composite_2018': ['min','max','mean','std','median'],\n",
    "})\n",
    "df_2017_2018_agg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_agg = df_2017_2018.agg({\n",
    "    'sat_participation_2018': ['min','max','mean','median','std'],\n",
    "    'sat_reading_2018': ['min','max','mean','median'],\n",
    "    'sat_math_2018': ['min','max','mean','median'],\n",
    "    'sat_total_2018': ['min','max','mean','median'],\n",
    "    'act_participation_2018': ['min','max','mean','median'],\n",
    "    'act_composite_2018': ['min','max','mean','median'],\n",
    "})\n",
    "df_2018_agg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what states show >50% participation on both tests for 2017?\n",
    "participation_total_2017 = df_2017_2018[(df_2017_2018['sat_participation_2017'] > 60) & (df_2017_2018['act_participation_2017'] > 50)][0:50]\n",
    "participation_total_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#satparticipation rate of 50 or more and score 1100 or greater \n",
    "state_part_comp = df_2017_2018[(df_2017_2018['sat_participation_2017'] > 50) & (df_2017_2018['sat_total_2017'] > 1100)][0:50]\n",
    "state_part_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "#D.C had an 8% drop YoY\n",
    "#Florida had the highest sat_participation absolute change YoY among all the states that had 80%+\n",
    "#Colorado offers free SAT but didnt even get an 80% participation rate. In 2017 thier participation rate was 11% in 2017 then increased to 28%\n",
    "\n",
    "participation_sat_2017 = df_2017_2018[(df_2017_2018['sat_participation_2017'] > 80)][0:50]\n",
    "participation_sat_2017[['state','sat_participation_2017','sat_total_2017', 'sat_participation_2018', 'sat_total_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorado had a 70% drop in particiation \n",
    "# states with free act testing made the list, Teenese and Minnesota dont offer free ACT  but still ranked top 15.\n",
    "\n",
    "participation_act_2017 = df_2017_2018[(df_2017_2018['act_participation_2017'] > 99)][0:50]\n",
    "participation_act_2017[['state','act_participation_2017','act_composite_2017', 'act_participation_2018','act_composite_2018']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.title('Relationships of Potential Interest', fontsize=24)\n",
    "#sns.dark_palette(\"palegreen\", as_cmap=True)\n",
    "corr = df_2017_2018.corr()\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr,mask=mask, cmap = sns.diverging_palette(240, 10, n = 13, as_cmap=True), center = True, annot = True,\n",
    "           vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize= (12,40))\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    \n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        ax[i].set_title(list_of_titles[i])\n",
    "    fig.tight_layout()    \n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_histograms(df_2017_2018, ['sat_participation_2017', 'sat_reading_2017', 'sat_math_2017',\n",
    "                   'sat_total_2017', 'act_participation_2017', 'act_english_2017',\n",
    "                   'act_math_2017', 'act_reading_2017', 'act_science_2017',\n",
    "                   'act_composite_2017', 'sat_participation_2018', 'sat_reading_2018',\n",
    "                   'sat_math_2018', 'sat_total_2018', 'act_participation_2018',\n",
    "                   'act_composite_2018'],\n",
    "                   ['SAT Participation 2017', 'SAT Reading 2017', 'SAT Math 2017', 'SAT Total 2017', 'ACT Participation 2017', \n",
    "                    'ACT English 2017',' ACT Math 2017', 'ACT reading 2017', 'ACT Science 2017', 'ACT Composite 2017',\n",
    "                   'SAT Participation 2018', 'SAT Reading 2018', 'SAT Math 2018', 'Sat Total 2018','ACT Participation 2018', 'ACT Composite 2018'],\n",
    "                   [])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next time Kiddo !!\n",
    "# df_2017_2018[['sat_participation_2017', 'sat_reading_2017', 'sat_math_2017',\n",
    "#        'sat_total_2017', 'act_participation_2017', 'act_english_2017',\n",
    "#        'act_math_2017', 'act_reading_2017', 'act_science_2017',\n",
    "#        'act_composite_2017', 'sat_participation_2018', 'sat_reading_2018',\n",
    "#        'sat_math_2018', 'sat_total_2018', 'act_participation_2018',\n",
    "#        'act_composite_2018']].hist();\n",
    "# plt.figure(figsize=(1000,1000))\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_2017_2018[['sat_math_2017','sat_math_2018']]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another fuck up\n",
    "# df_2017_2018.iloc[:,1:].hist()\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.show();\n",
    "df_2017_2018_agg.plot(kind=\"line\", figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_2017_2018['sat_participation_2017'].hist();\n",
    "\n",
    "#Participation rates for SAT & ACT\n",
    "fig, ax = plt.subplots(nrows = 2, ncols=2, figsize=(10,10))\n",
    "df_2017_2018['sat_participation_2017'].plot(kind='hist', ax= ax[0,0], title='SAT Participation 2017')\n",
    "df_2017_2018['sat_participation_2018'].plot(kind='hist', ax= ax[0,1], title='SAT Participation 2018')\n",
    "df_2017_2018['act_participation_2017'].plot(kind='hist', ax= ax[1,0], title='ACT Participation 2017')\n",
    "df_2017_2018['act_participation_2018'].plot(kind='hist', ax= ax[1,1], title='ACT Participation 2018')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Math scores for SAT & ACT\n",
    "fig, ax = plt.subplots(nrows = 2, ncols=2, figsize=(10,10))\n",
    "df_2017_2018['sat_math_2017'].plot(kind='hist', ax= ax[0,0], title='SAT Math 2017')\n",
    "df_2017_2018['sat_math_2018'].plot(kind='hist', ax= ax[0,1], title='SAT Math 2018')\n",
    "df_2017_2018['act_math_2017'].plot(kind='hist', ax= ax[1,0], title='ACT Math 2017')\n",
    "#df_2017_2018['act_math_2018'].plot(kind='hist', ax= ax[1,1], title='ACT Math 2018')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading/verbal scores for SAT & ACT\n",
    "fig, ax = plt.subplots(nrows = 2, ncols=2, figsize=(10,10))\n",
    "df_2017_2018['sat_reading_2017'].plot(kind='hist', ax= ax[0,0], title='SAT Reading 2017')\n",
    "df_2017_2018['sat_reading_2018'].plot(kind='hist', ax= ax[0,1], title='SAT Reading 2018')\n",
    "df_2017_2018['act_reading_2017'].plot(kind='hist', ax= ax[1,0], title='ACT Reading 2017')\n",
    "df_2017_2018['act_english_2017'].plot(kind='hist', ax= ax[1,1], title='ACT English 2017')\n",
    "fig.tight_layout()\n",
    "\n",
    "# In [41]:\n",
    "# SAT_ACT.hist(column='Reading_ACT', xlabelsize=30, ylabelsize=30, figsize=(20,10), bins=20)\n",
    "# plt.xlabel('ACT Verbal Scores', fontsize=20)\n",
    "# plt.ylabel('Number of States', fontsize=20)\n",
    "# plt.title('ACT Verbal Reading Scores Across the 50 States')\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2017_2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.groupby('state')['sat_participation_2017'].mean().plot(kind=\"line\", figsize=(15,10));\n",
    "# just fucking aorund here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comparing two non-time quantitavie variables\n",
    "# I see that outlier at iloc[20,3]\n",
    "                   \n",
    "df_2017_2018.plot.scatter(x='sat_participation_2017',\n",
    "                          y='sat_math_2017',\n",
    "                          c='red', title='SAT Math Scores v. Participation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.plot.scatter('sat_reading_2017', 'sat_participation_2017')\n",
    "plt.xlabel('sat reading 2017', fontsize=15)\n",
    "plt.ylabel('sat participation 2017', fontsize=15)\n",
    "plt.title('SAT reading v. Participation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT total/composite scores for 2017\n",
    "\n",
    "df_2017_2018.plot.scatter('sat_total_2017', 'act_composite_2017', c='r')\n",
    "plt.xlabel('sat_total_2017', fontsize=15)\n",
    "plt.ylabel('act_composite_2017', fontsize=15)\n",
    "plt.title('SAT Total v. ACT Composite');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Total scores for SAT 2017 vs. 2018\n",
    "cat=fig.gca()\n",
    "\n",
    "cat = df_2017_2018.plot(kind='scatter', x='sat_total_2017', y='sat_participation_2017', color='darkgreen',\n",
    "                 label='SAT 2017 Group', title= 'Score v. Participaion 2017-2018')\n",
    "\n",
    "\n",
    "# df_2017_2018.plot(kind='scatter', x='sat_total_2018', y='sat_participation_2018', color='red',\n",
    "#                  label='SAT 2018 Group', ax= cat)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.plot(kind='scatter', x='sat_total_2018', y='sat_participation_2018', color='red',\n",
    "                 label='SAT 2018 Group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total scores for SAT 2017 vs. 2018\n",
    "cat=fig.gca()\n",
    "\n",
    "cat = df_2017_2018.plot(kind='scatter', x='sat_total_2017', y='sat_participation_2017', color='darkgreen',\n",
    "                 label='SAT 2017 Group', title= 'Score v. Participaion 2017-2018')\n",
    "\n",
    "df_2017_2018.plot(kind='scatter', x='sat_total_2018', y='sat_participation_2018', color='red',\n",
    "                 label='SAT 2018 Group', ax= cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participation_sat_2017.plot(kind='scatter', x='sat_participation_2017', y='sat_total_2017', color='blue',\n",
    "                  label='SAT 2017 Group', title= 'States with SAT participation rate over 80% ');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vax = participation_act_2017.plot(kind='scatter', x='act_participation_2017', y='act_composite_2017', color='orange',\n",
    "                 label='ACT 2017 Group', title= 'States with ACT participation rate over 90%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vax=fig.gca()\n",
    "\n",
    "vax =participation_sat_2017.plot(kind='scatter', x='sat_participation_2017', y='sat_total_2017', color='blue',\n",
    "                  label='SAT 2017 Group', title= 'States with SAT participation rate over 80% ')\n",
    "participation_act_2017.plot(kind='scatter', x='act_participation_2017', y='act_composite_2017', color='orange',\n",
    "                 label='ACT 2017 Group', title= 'States with ACT participation rate over 90%', ax=vax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "#\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax = sns.boxplot(df_2017_2018.act_science_2017, orient='h',\n",
    "                fliersize=8, linewidth=1.5, notch=False,\n",
    "                saturation=0.5, ax=ax)\n",
    "\n",
    "ax.set_ylabel('ACT science 2017', fontsize=16)\n",
    "ax.set_title('ACT science scores 2017\\n', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows me the outlier, fucking maryland\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.stripplot(x=\"act_science_2017\", y=df_2017_2018.iloc[18:22,0], data=df_2017_2018);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax = sns.boxplot(df_2017_2018.sat_math_2017, orient='h',\n",
    "                fliersize=8, linewidth=1.5, notch=False,\n",
    "                saturation=0.5, ax=ax)\n",
    "\n",
    "ax.set_ylabel('sat math 2017', fontsize=16)\n",
    "ax.set_title('SAT scores 2017\\n', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw a boxplot with nested grouping by two categorical variables; not very useful... maybe change the variables\n",
    "fig= plt.figure(figsize=(30,15))\n",
    "ax= fig.gca()\n",
    "ax= sns.boxplot(x=\"sat_participation_2018\", y=\"sat_math_2018\", color=\"blue\",\n",
    "                  data=df_2017_2018, palette=\"Set3\", ax=ax)\n",
    "ax.set_title('SAT math scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax = sns.boxplot(data=df_2017_2018, orient='h', fliersize=10, linewidth=3, notch=True,\n",
    "                 saturation=0.5, ax=ax)\n",
    "\n",
    "ax.set_title('All variables boxplot\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Answers: This Exploratory Data Analysis were based on 17 different variables, see data frame below. There were some missing variables that would help us determine a deeper interpretation. The data for the ACT test in 2018 is missing data on the 4 sections of the test: Math, Science, English, Reading. \n",
    "\n",
    "SAT participation in 2017 has a histogram with a skew to the right and you can easily see this in the mean v. median. When the mean is greater than the median you will get a histogram to the right. The standard deviation is .035, which is a large deviation, and thats why you see such a large number on participation plotted farther away from the mean. \n",
    "\n",
    "SAT reading 2017 has a median larger than the mean which should give us a histogram skewed to the left. However, when you plot this graph it shows like its skewed to the right and I believe the data skewed to the right because of the high standard deviation of 45.\n",
    "\n",
    "SAT Math 2017 have a mean and a median that are very close. This proximity would normally suggest that this data is evenly distributed. However, when this histogram is plotted it gives us a graph skewed to the right. The standard deviation for this data frame is at 84.\n",
    "\n",
    "SAT total 2017 has the mean greater than the median, when interpreted just by those two numbers you can assume that this graph will skew to the right. When we plot the histogram we do see that skew to the right. \n",
    "\n",
    "ACT participation 2017 has a median that is greater than the mean which should plot a histogram skewed to the left. When we see the actual plot we do get that skew to the left and that is mainly due to some states having 100% participation rates.\n",
    "\n",
    "ACT english 2017 has a median that is really close to the mean. This relationship will plot a histogram that is evenly distributed. The standard deviation here is really low, so thats another clue that will tell us the distribution will be normal.\n",
    "\n",
    "ACT math 2017 has a median that is only .2 points away. This relationship between the mean and median, along with the low standard deviation of 2.3, will plot a normal distribution.\n",
    "\n",
    "ACT reading 2017 has a mean greater than the median, but only by .2 points. Again, we will see a histogram with a normal distribution, considered the standard deviation of 2.06.\n",
    "\n",
    "ACT science 2017 the mean and media are only .2 points from one another. The .2 difference will tell us that the histograph will have a normal distribution, backed by the 3.2 standard deviation. \n",
    "\n",
    "ACT composite 2017 has a mean pretty much equal to its median. This is the collection of all the variables of ACT so it would make sense that this would plot as a normal distribution histograph. If you need further proof look at the standard deviation of 2.02\n",
    "\n",
    "SAT participation 2018 has higher mean, median, and standard deviation from 2017. This distribution is skewed to the right and thats mainly to the lower participating states. This data does have a high standard deviation of 37, which is just over 2 points from 2017. So the YoY increase in participation is dismal.\n",
    "\n",
    "SAT reading 2018  has a mean greater than the median, by about 13 points. Include the high standard deviation of 45 and we see a histograph skewed to the right. \n",
    "\n",
    "SAT math 2018 has a mean greater than the median with a standard deviation of 49.5. When we look at the histograph and see that a lot of the data plots along the mean of all the scores for 2018. \n",
    "\n",
    "SAT total 2018 total is skewed to the right. We have a mean that is greater than the median. Some outliers are seen here that come from the performances from certain states.\n",
    "\n",
    "ACT participation 2018 is skewed to the left. The median is greater than the mean. This median comes from 13 states having a 100% participation rate. \n",
    "\n",
    "ACT composite 2018 has all the variables to plot a nor distributed histogram, but when we look the graph it looks like it has two tails. The range of scores is so small that it throws the graph of from what the mean, median, and standard deviation conclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all the stats for the descriptive summary above\n",
    "df_2017_2018_agg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No, most charts show that individual score and participation rates are skewed. The only numbers that are normally didstributed are the totals/composite values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "Math- SAT has the data that show a normal distribution. ACT math 2018 holds a normal distribution. \n",
    "Reading- We dont see a normal distribution for either test. \n",
    "Rates- skewed and I believe it all depends on how the states handle these tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*\n",
    "\n",
    "I would think that it would could use statistical inference to find something like a confidnece interval. If you take a sample from the math scores, science scores, or the total score this would show a good representation of the population. We could arrive to different conclusion about population parameters based on samples from each of these variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores? \n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Inference wouldnt work on these two data sets because they dont follow the Gaussian curve, in which case parametric tests are applied.  I see these scores as unpaired becuase SAT math scores and ACT math scores have no possibility of one influencing the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "sat_part_mean = np.mean(df_2017_2018['sat_participation_2017'])\n",
    "act_part_mean = np.mean(df_2017_2018['act_participation_2017'])\n",
    "sat_part_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_part_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_data = df_2017_2018['sat_participation_2017'][0:50]\n",
    "act_data = df_2017_2018['act_participation_2017'][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(sat_data, act_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value is less than or equal to the alpha (p< .05), then we reject the null hypothesis, and we say the result is statistically significant. \n",
    "The p value is less than alpha, we fail to reject the null hypothesis, so we reject the null hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorado had a 70% drop in particiation \n",
    "# states with free act testing made the list, Teenese and Minnesota dont offer free ACT  but still ranked top 15.\n",
    "#Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "#D.C had an 8% drop YoY\n",
    "#Florida had the highest sat_participation absolute change YoY among all the states that had 80%+\n",
    "#Colorado offers free SAT but didnt even get an 80% participation rate. \n",
    "#In 2017 thier participation rate was 11% in 2017 then increased to 28%\n",
    "# 8 states offer Free SAT\n",
    "#16 states \n",
    "cat=fig.gca()\n",
    "\n",
    "cat = df_2017_2018.plot(kind='scatter', x='sat_total_2017', y='sat_participation_2017', color='darkgreen',\n",
    "                 label='SAT 2017 Group', title= 'Score v. Participaion 2017-2018')\n",
    "\n",
    "df_2017_2018.plot(kind='scatter', x='sat_total_2018', y='sat_participation_2018', color='red',\n",
    "                 label='SAT 2018 Group', ax= cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reccomned that we could really increase participation rates by making the ACT the test requeired for admissions. Michigan is a perfect example. Professor Hyman from the Unviserity of Michigan studied the effects of 'free ACT testing', he did a study tracking this data. Michigan began requiring public school juniors to take the ACT in 2007, and the share of high school graduates taking a college entrance exam rose immediately to nearly 99 percent from 54 percent. That growth was even sharper among low-income students; only 35 percent had been taking the test. Professor Hyman also found for every 1,000 students who took a college exam when it was optional, and scored high enough to attend a selective college, another 230 high scorers appeared once the test was mandatory. For low-income students, the effect was larger: For every 1,000 students who scored well on the optional test, an additional 480 did so on the mandatory test. Jumpforward ten years and you see that Michigan's ACT numbers composite scores are among the highest in the nation and score 3 points above the mean for either years. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018.iloc[22][['state','act_composite_2017','act_composite_2018']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2018[['state','act_composite_2017','act_composite_2018']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
